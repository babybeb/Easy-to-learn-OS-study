# 가상 메모리 관리

메모리 관리자는 프로세스가 필요로 하는 데이터를 언제 메모리로 가져올지 결정하는 <b>_가져오기 정책_</b>

가져온 프로세스를 메모리의 어느 위치에 올려놓을지 결정하는 <b>_배치 정책_</b>

메모리가 꽉 찼을 때 메모리 내에 있는 어떤 프로세스를 내보낼지 결정하는 <b>_재배치 정책_</b>

에 따라 메모리를 관리한다.

<br />

<br />

## 요구 페이징

프로세스가 필요로하는 데이터를 언제 메모리로 가져올지 결정하는게 가져오기 정책이다.

가져오기 정책은 프로세스가 요청할 때 메모리로 가져오는 방법이 일반적이며 이를 <b>_요구 페이징(demand paging)_</b> 이라 한다.

사용자가 요구할 때 해당 페이지를 메모리로 가져오는 것을 요구 페이징이라 한다.

요구 페이징의 장점

- 메모리 절약
- 메모리의 효율적 관리
- 프로세스의 응답 속도 향상

요구 페이징과 반대로 앞으로 필요한걸 예상해서 미리 가져오는걸 미리 가져오기 라고 한다. 대표적인 예는 캐시이다.

캐시는 필요할것으로 예상되는 데이터를 미리 캐시 메모리에 가져다 놓음으로써 시스템의 성능을 향상하지만, 그 데이터가 쓸모없을 경우 비효율적이다.

따라서 현대 운영체제는 요구 페이징을 기본으로 사용한다.

<br />

### 스와핑과 게으른 스와퍼

프로세스 입장에서는 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리 올리는게 좋음.

이런 방식을 _순수한 스와핑(swapping)_ 이라하고 사용자가 요구할 떄 메모리에 올리는 걸 _게으른 스와퍼(lazy swapper)_ 라고 함.

<br />

## 페이지 테이블 엔트리의 구조

가상 메모리의 크기는 물리 메모리 크기 + 스왑 영역 크기 이다.

스왑영역은 하드디스크에 존재하나 메모리 관리자가 관리하는 영역임

스왑 영역에서 물리 메모리로 데이터를 가져오는 걸 _스왑 인_, 물리 메모리에서 스왑 영역으로 데이터를 내보내는 걸 _스왑 아웃_ 이라고 한다.

가상 메모리 시스템에서 사용자의 프로세스는 물리 메모리 또는 스왑영역 중 한 곳에 있다.

페이지가 스왑 영역에 있는 경우는 크게 두가지인데

1. 요구 페이징으로 인해 처음부터 물리 메모리에 못 올라감.
2. 메모리가 꽉 차서 스왑영역으로 옮겨짐.

어떤 경우든 페이지 테이블에는 페이지가 물리메모리에 있는지 스왑영역에 있는지 표시해야 하는데 이떄 사용하는 비트가 _유효 비트_ 이다.

<br />
<br />

# 페이지 교체 알고리즘

프로세스가 페이지 요구 -> 현재 메모리에 없으면 페이지 부재 발생 -> 스왑영역에서 페이지를 메모리로 올림 -> 메모리 꽉 찼다면 메모리에 있는 페이지를 내보내고 스왑영역에 있는 페이지를 올려야 함.

페이지 교체 알고리즘은 위 과정에서 스왑 영역으로 보낼 페이지를 결정하는 알고리즘이다.

<br />

## 무작위 페이지 교체 알고리즘(random page replacement algorithm)

- 무작위로 선정한다.
- 지역성을 고려하지 않아서 성능이 안좋음

<br />

## FIFO 페이지 교체 알고리즘(First In First Out page replacement algorithm)

- 큐로 구현하고 가장 먼저 들어온 페이지를 스왑 영역으로 내림
- 무조건 가장 들어온지 오래된 페이지를 대상으로 하기 때문에 성능이 떨어진다.

<br />

## LRU 페이지 교체 알고리즘(Least Recently Used page replacement alrogithm)

- 메모리에 올라온 페이지중 가장 오랫동안 사용되지 않은 페이지를 스왑영역으로 보낸다.
- 페이지에 읽기, 쓰기, 실행과 같은 연산이 이루어진 시간을 기준으로 한다.
- 장점
  - 가장 오랫동안 사용하지 않은 페이지를 대상으로 하기 때문에 효율적임. (일반적으로 FIFO 보다 나은 성능)
- 단점
  - 접근 시간, 참조 비트를 유지하기 위한 메모리 낭비

<br />

## LFU 페이지 교체 알고리즘(Least Frequently Used page replacement algorithm)

페이지가 몇번 사용되었는지를 기준으로 선정한다.

페이지 접근 횟수를 표시하는데 추가 공간이 필요하므로 메모리 낭비

<br />

## NUR 페이지 교체 알고리즘(Not Used Recently page replacement algorithm)

- 성능 좋고 메모리 낭비 적고 쉽게 구현 가능해서 가장 많이 사용된다.
- 페이지마다 참조 비트와 변경 비트를 가진다.
  - 참조 비트 : 페이지에 접근(read / execute) 하면 1이 된다.
  - 변경 비트 : 페이지가 변경(write / append) 되면 1이 된다.

```json
(0, 0) // 초기값은 0, 0 으로 시작 앞에 값이 참조 비트 뒤에 값이 변경 비트

(1, 0) // 페이지에 읽기 또는 실행 같은 접근이 발생하면 참조 비트를 1로 바꿈

(0, 1) // 페이지에 쓰기 또는 추가 같은 변경이 일어나면 변경 비트를 1로 바꿈

(1, 1) // 두 가지 다 하면 둘 다 바꿈

// 페이지 교체 대상 우선순위
(0, 0) > (0, 1) > (1, 0) > (1, 1) // 만약 모든 페이지가 (1, 1) 이 되면 모든 페이지를 (0, 0) 으로 reset 한다.

```

<br />
<br />

# 스레싱과 프레임 할당

하드디스크의 입출력이 너무 많아져서 잦은 페이지 부재로 작업이 멈춘 것 같은 상태를 <b>_스레싱(threshing)_</b> 라고 한다.

스레싱은 멀티프로그램 수와 관계가 있다.

> 멀티프로그래밍 정도(degree of multiprogramming) : 동시에 실행하는 프로그램의 정도 -> 너무 높으면 스레싱 발생

- 스레싱 발생 지점(threshing point) : 메모리가 꽉 차면 CPU가 작업하는 시간보다 페이징하는게 너무 많아져서 CPU가 작업을 할 수 없는 상태

<br />

## 물리 메모리를 늘리면 왜 컴퓨터가 빨라질까?

운영체제는 동시에 많은 프로그램을 실행하는데 물리 메모리가 작다면 스레싱 지점에 빨리 도달하므로 성능이 느려짐

메모리의 크기를 늘리면 스레싱 발생 지점이 늦춰지므로 성능이 향상된다.

<br />

## 정적 프레임 할당(static allocation)

프로세스 실행 초기에 프레임을 나누어준 후 그 크기를 고정하는 방식.

- 균등 할당 방식(equal allocation)
  - 프로세스의 크기와 상관없이 사용 가능한 모든 프레임을 모든 프로세스에 균등하게 할당.
  - 단점
    - 크기가 큰 프로세스는 필요한 만큼 프레임을 할당 받지 못해서 페이지 폴트 발생
    - 크기가 작은 프로세스의 경우 메모리 낭비 발생
- 비례 할당 방식(proportional allocation)
  - 프로세스 크기에 비례하여 프레임을 할당하는 방식
    - 프로세스가 필요로하는 프레임을 유동적으로 변경 불가능
    - 사용하지 않을 메모리를 처음부터 확보하여 공간 낭비

<br />

## 동적 프레임 할당(dynamic allocation)

프로세스 실행 중 어떨때는 많은 프레임을, 어떨때는 작은 프레임만이 필요하기 때문에 이처럼 시시각각 변하는 요청을 수용하는 방식이다.

- 작업집합 모델(working set model)
  - 지역성 이론을 바탕으로, 가장 최근에 접근한 프레임이 이후에도 또 참조될 가능성이 높다는 가정하에 출발.
  - 최근 일정시간 동안 참조된 페이지들을 집합으로 만들고 물리 메모리에 유지하여 프로세스의 실행을 돕는다.
    - 작업집합에 포함되는 페이지 범위를 작업집합 윈도우(Working Set Window, WSW) 라 한다.
  - 작업집합 윈도우에는 현재 시점부터 시간적으로 가까운 페이지부터 삽입된다.
  - 작업집합 크기가 5라는것은 페이지에 다섯 번 접근할 때마다 작업집합을 갱신한다는 의미이다.
  - 작업집합 윈도우의 크기에 따라 프로세스의 실행 성능이 달라진다.

<br />

- 페이지 부재 빈도(page fault frequency)
  - 페이지 폴트 횟수를 기록하여 페이지 폴트 비율의 상한선과 하한선을 설정하는 방식이다.
  - 페이지 폴트 비율이 상한선을 초과하면 할당한 프레임이 적다는 뜻이므로 프레임을 추가하여 늘린다.
  - 페이지 폴트 비율이 하한선 밑으로 내려가면 메모리가 낭비된다는 뜻이므로 할당한 프레임을 회수한다.

<hr >

## q1. 가상 메모리란?

프로세스의 사용하는 부분만 메모리에 올리고 나머진 디스크(스왑영역) 에 보관하는 기법

## q2. 페이지란?

가상 메모리 시스템에서 프로세스를 일정 크기로 나누게 되는데 이떄 정해진 한번에 읽어들이는 단위를 페이지라고 한다.

## q3. 페이지 테이블이란?

가상 주소와 물리 주소를 매핑하는 테이블, 가상 주소는 프로세스 내부에서 사용하는 주소, 물리 주소는 메모리에 실제 주소, 가상 주소 -> 물리 주소로 바꿔주는 역할

## q4. 페이지 교체 알고리즘이란?

CPU가 메모리에서 페이지를 가져올 때, 페이지 폴트가 발생하면 어떤 페이지를 스왑영역으로 내보낼지 결정하는 것
페이지 교체 알고리즘은 페이지 교체가 가장 적게 일어나면서 자주 쓰는 페이지는 유지되게끔 하는게 목표임

## q5. TLB 란?

CPU가 메모리에 접근할 때 페이지 테이블을 참조하는데 이때 자주 참조하는 가상 주소 -> 물리 주소를 미리 가지고 있는 캐시이다.
TLB에 필요한 물리주소가 있으면 TLB hit(캐시 힛) 이어서 바로 가져다 쓰면 되고 없으면 TLB miss(캐시 미스) 여서 페이지 테이블에 물어본다.

## q6. MMU(메모리 관리 장치) 란?

가상 주소를 실제 물리 주소로 변환하는 작업을 주도적으로 한다. TLB는 MMU 안에 존재하는 캐시 메모리

## q7. 스레싱이란?

CPU가 실제 프로세스를 처리하는 시간보다 페이지 교체에 드는 비용이 더 많아지는 현상

발생 이유 : 페이지 하나당 차지할 수 있는 메모리의 양이 적기 때문에 페이지 교체에 드는 비용이 많아져서

해결 방법 : 페이지 교체는 적게 발생시키고, 자주 사용되는 페이지는 메모리에 계속 유지되게 해야 함
