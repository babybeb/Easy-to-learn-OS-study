# 가상 메모리 관리

### 요구페이징이란?

프로그램 실행에 필요한 부분만 프로세스로 메모리에 올린 후 특정 기능이 필요할 때 해당 데이터를 가져오는 걸 요구페이징(demand-paging)이라고 한다. 캐시와 비슷하게 동작하는 미리 가져오기(pre-fetch)도 있는데 필요할 것으로 예상되는 데이터를 미리 메모리에 가져다 놓는 방식이다.

### PTE의 구조

![](https://velog.velcdn.com/images/jsb100800/post/9eba33ae-20ed-4004-96f2-95147caaa577/image.png)

Page 테이블의 Entry는 페이지 번호, flag bit, 프레임 번호로 구성된다.

- 접근 비트(access bit) : 페이지가 메모리에 올라온 후 사용한 적이 있는지 알려주는 bit, reference bit라고도 한다.

- 변경 비트(modify bit) : 페이지가 메모리에 올라온 후 데이터 변경이 있었는지를 알려주는 bit이다. dirty bit라고도 한다.

- 유효 비트(valid bit) : 페이지가 실제 메모리에 있는지를 나타내는 bit이다. present bit라고도 한다.

- 읽기, 쓰기, 실행 비트 : 페이지에 대한 접근 권한을 나타내는 bit이다. 합쳐서 right bit라고도 한다.

### Page Fault

![](https://velog.velcdn.com/images/jsb100800/post/ae61e322-c6d8-412b-b6e2-ff896db11db6/image.png)

PTE의 valid bit가 0일 경우에는 주소필드에 프레임 번호가 저장되지만, 1일 경우에는 swap 영역인 저장장치 내의 주소가 저장된다. 따라서 요구페이징이 일어날 때, MMU는 valid bit를 확인하고 0이면 해당 프레임에서 데이터를 가져오고 1일 경우에는 해당 swap 영역으로 가서 데이터를 메모리로 swap in하고 valid bit를 0으로 바꾸는 update를 한다.

![](https://velog.velcdn.com/images/jsb100800/post/2a63e58c-efee-4d42-a9e0-469e4b1fe9c3/image.png)

그렇다면, 메모리가 가득차 있는 상태에서는 어떻게 작동할까?

![](https://velog.velcdn.com/images/jsb100800/post/5655207c-f5ed-4e7d-91b2-78a5d90aea80/image.png)

1. MMU가 해당 PTE의 valid bit가 1인것을 확인해 page fault 발생
2. 메모리가 가득 차 있기 때문에 메모리의 페이지 중 하나를 swapu out 한다.
3. swap out한 페이지의 valid bit를 1로 update하고 주소 필드값을 swap영역의 해당 주소로 update한다.
4. 요구페이징이 일어나 가져오려던 데이터를 빈 프레임으로 swap in 한다.
5. 해당 페이지의 valid bit와 주소 필드를 update 한다.

### 지역성

메모리가 공간이 부족해 기존 페이지를 swap out 할 때는 되도록 앞으로 사용하지 않을 페이지를 고르는게 좋다. 이러한 페이지를 고르는 알고리즘은 지역성을 기반으로 페이지를 고른다.

- 공간 지역성 : 현재 위치에서 가까운 데이터에 접근할 확률이 높다.
- 시간 지역성 : 최근에 접근한 데이터에 다시 접근할 확률이 높다.
- 순차 지역성 : 여러 작업이 순차적으로 진행되는 경향이 있다.

지역성 개념은 캐시에도 활용된다.

### 페이지 교체 알고리즘

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled.png)

#### 성능 평가 기준

Page Fault가 일어난 횟수, 페이지 요청 후 실행 전 까지의 평균 대기 시간, 전체작업에 걸리는 시간 등 다양하다. 여기서는 메모리 접근 패턴을 사용하여 Page Fault가 일어난 횟수와 페이지 성공 횟수로 비교한다.

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%201.png)

#### Random Page Replacement(무작위 페이지 교체)

지역성을 전혀 활용하지 않기 때문에 자주 사용하는 페이지도 얼마든지 swap out될 수 있어서 성능이 나빠 거의 사용하지 않는다.

#### FIFO(First In First Out)

시간상으로 메모리에 가장 먼저 들어온 페이지를 swap out 하며, 큐로 구현된다.

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%202.png)

PageFault가 7번 발생했고 성공은 3번 발생했다.(3/10)

FIFO 알고리즘은 가장 오래된 페이지를 swap out 한다는 점에서 시간지역성을 어느정도 따르는 것 처럼 보이지만, 오래됐음에도 불구하고 자주 사용하는 페이지도 있고 올라온지 얼마 안됐지만 거의 사용하지 않는 페이지도 있으므로 성능이 다소 떨어진다.

### Optimal Page Replacement(최적 페이지 교체)

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%203.png)

앞으로 사용되지 않을 페이지를 예상하며 해당 페이지를 swap out하는 알고리즘인데, 실제로 이를 완벽히 예측하는건 불가능하므로 이론적인 알고리즘이다. 이것을 근사하게 구현한 알고리즘으로 LRU(Least Recently Used) 알고리즘과 LFU(Least Frequently Used) 알고리즘, NUR(Not Used Recently) 알고리즘이 있다.

### LRU(Least Recently Used)

메모리에 올라온 후 가장 오랫동안 사옹되지 않은 페이지를 대상 페이지로 선정한다. 시간을 기준으로 구현할 수 있으며 카운터나 reference bit(access bit)를 사용하는 방법도 있다. 메모리 공간을 다소 낭비한다는 단점이 있다.

#### 페이지 접근 시간에 기반한 구현

페이지에 접근한 지 가장 오래된 페이지를 교체 하는 방식이다.

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%205.png)

PageFault가 6번 발생했고 성공은 4번 발생했다.(4/10)

#### 카운터에 기반한 구현

시간 대신 카운터 숫자를 기반으로 구현

#### reference bit shift 방식

각 페이지에 일정 크기의 reference bit를 만들어 사용한다. 초기값은 0이고, 해당 페이지에 접근 할 때마다 1로 바뀌며, 주기적으로 오른쪽으로 한칸 씩 이동한다.

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%206.png)

참조 비트 중 가장 작은 값을 swap out 하면 된다.

### LFU(Least Frequently Used)

최소 빈도 사용 알고리즘이라고도 하며, 해당 페이지가 몇 번 사용되었는지를 선정 기준으로 한다.

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%207.png)

PageFault가 5번 발생했고 성공은 5번 발생했다.(5/10)

일반적으로 LRU, LFU의 성능은 비슷하고 FIFO보다는 우수하다고 알려져 있다.
LRU, LFU 알고리즘의 단점은 추가적인 메모리 공간이 필요하다는 점이다.

### NUR(Not Used Recently)

최근에 사용되지 않은 페이지를 선정 기준으로 삼는 알고리즘인데, LRU, LFU 와 성능은 비슷하면서 추가적인 메모리를 필요로 하지 않는다.

접근한 횟수의 차이가 크다면 당연히 적게 접근한 페이지를 swap out 해야하지만 차이가 크지 않다면 어떤 페이지를 swap out 해도 큰 영향은 없다. 이를 바탕으로 추가 비트 2개만 사용하며 근사치를 저장한다.

reference bit와 modify bit의 순서쌍으로 swap out 할 페이지를 선정한다.

초기 상태는 (0, 0)이며 접근이 있거나 수정이 있으면 해당 비트가 1로 바뀐다.

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%208.png)

제일 먼저 (0, 0)인 페이지를 찾고 그 다음은 (0, 1)인 페이지를, 그 다음은 (1, 0)인 페이지를 찾고 마지막으로 모든 페이지가 (1, 1)이 된다면 전체 순서쌍을 초기화 한다.

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%209.png)

PageFault가 5번 발생했고 성공은 5번 발생했다.(5/10)

NUR 알고리즘의 경우는 LRU, LFU와 성능은 비슷하면서 추가적으로 필요한 메모리 공간이 매우 적어서 가장 많이 사용되고 있다.

### FIFO 변형 알고리즘

FIFO 알고리즘은 메모리에 올라온 순서만 고려하고 사용 빈도를 고려하지 않기 때문에 성능이 좋지 않다. 이를 개선한 second chance 페이지 교체 알고리즘과 clock 알고리즘이 있다.

#### Second Chance

FIFO와 마찬가지로 큐를 적용하지만 특정 페이지에 접근하면 해당 페이지를 큐의 가장 뒤쪽으로 보낸다는 점에서 다르다.

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%2010.png)

PageFault가 6번 발생했고 성공은 4번 발생했다.(4/10)

일반적으로 성능은 LRU, LFU, NUR과 FIFO의 사이에 있는걸로 알려져 있다.

#### Clock

FIFO와 다르게 원형큐를 사용하며, 추가적으로 reference bit를 사용한다.

원형큐를 사용하므로 시작과 끝이 불분명하므로 포인터를 사용하는데, 포인터를 이동하면서 swap out할 페이지를 찾다가 reference bit가 0인 페이지를 발견하면 swap out 한다. reference bit는 1인 페이지를 발견하면 해당 페이지를 건너뛰는 이때 reference bit를 0로 변경해 다음번에 다시 만나게 되면 swap out 되도록 한다.

![](https://yansigit.github.io/posts/%ed%8e%98%ec%9d%b4%ec%a7%80-%ea%b5%90%ec%b2%b4-%ec%95%8c%ea%b3%a0%eb%a6%ac%ec%a6%98/Untitled%2012.png)

PageFault가 6번 발생했고 성공은 4번 발생했다.(4/10)

포인터와 각 페이지당 reference bit 하나만 추가하면 되기 때문에 NUR 페이지 교체 알고리즘보다 추가 공간이 적지만 알고리즘이 복잡하고 계산량이 많다는 단점이 있다.

### Thrashing

PageFault가 너무 자주 발생해 swap 작업이 많아져 성능이 낮아지는 상태를 Trrashing이라고 한다. 동시에 실행하는 프로그램의 수를 멀티프로그래밍 정도(degree of multiprogramming)이라고 하는데, 이게 너무 높으면 Thrashing이 발생한다.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FVsWVK%2FbtrmKZk8Pwo%2F8zHt8LEjKaQZebHTFGD3f1%2Fimg.png)

물리메로리를 늘리면 Thrashing이 발생하는 지점이 늦춰지게 되는데 물리메모리가 충분히 커서 Thrashing만 발생하지 않는다면 그 이후에는 크기가 아무리 커져도 성능상으로 차이가 없다.

Thrashing은 페이지별로 프레임을 얼마나 할당하는지와도 연관있는데, 남아 있는 프레임을 실행 중인 프로세스에 적절히 나누어 주는 정책이 필요하다. 프로세스에 프레임을 할당하는 방식은 정적 할당과 동적 할당으로 구분된다.

### 정적 할당

프로세스 실행 초기에 프레임을 나눠 준 후 그 크기를 고정하는 방식

#### 균등 할당

프로세스의 크기와 상관없이 사용 가능한 프레임을 모든 프로세스에 동일하게 할당하는 방식.

![](https://velog.velcdn.com/images/chappi/post/f3c4e442-1ff4-42d6-8555-968db0c9cfdd/image.png)

프로세스의 크기와 상관없이 균등하게 할당하므로 프로세스가 큰 경우에는 PageFault가 빈번하게 발생하고, 프로세스가 작은 적은에는 메모리가 낭비된다.

#### 비례 할당

프로세스 크기에 비례하여 프레임을 할당하는 방식.

![](https://velog.velcdn.com/images/chappi/post/ee0ec64f-81ec-4719-a037-bd751d58be23/image.png)

- 프로세스가 실행 중에 필요로 하는 프레임을 유동적으로 반영하지 못한다.

- 사용하지 않은 메모리를 처음부터 확보하여 공간을 낭비한다.

### 동적 할당

정적 할당을 프로세스를 실행하면서 변동하는 메모리 요구를 반영하지 못하는 단점이 있다. 동적 할당은 이를 해결한 방식이다. working set model과 page fault frequency를 이용하는 방식이 있다.

#### Working Set Model

지역성 이론을 바탕으로 하며, 가장 최근에 접근한 프레임이 이후에도 또 참조될 가능성이 높다는 가정에서 출발한다.

![](https://velog.velcdn.com/images/chappi/post/1aee55fc-6a66-434d-9311-d6c07be8e607/image.png)

working set model에서 물리 메모리에 유지할 페이지의 크기를 working set size라고 하는데, 이는 작업 집합에 들어갈 최대 페이지 수를 의미한다. 위 그림에서는 5로 설정했다.

working set에 포함되는 페이지의 범위를 working set window(WSW)라고 하는데, 현재 시점에 최대 어느 범위까지의 페이지를 살펴볼 것인가를 결정하는 것이 WSW이다. 위 그림에는 10으로 설정했다. t1동안 참조된 10개 페이지 중 working set에서는 {1, 7, 5, 2, 3}이 삽입되며, 이 페이지들은 다음번 윈도우에 도달한 때 까지 물리 메모리에 보존된다. WSW에는 현재 시점부터 시간적으로 가까운 페이지부터 삽입된다.

working set size는 working set에 들어갈 최대 페이지 수를 말하지만 얼마나 자주 작업집합을 갱신할 것인지도 의미한다. working set size가 5라는 말은 페이지에 5번 접근할 때 마다 working set을 갱신한다는 의미이다.

![](https://velog.velcdn.com/images/chappi/post/fcaf9bab-e340-4801-872f-65451da3d52a/image.png)

t2 시점에 새롭게 5개 페이지에 접근했으므로 WSW를 살펴본 후, working set이 갱신된다.

working set model에서는 WSW의 크기에 따라 프로세스의 실행성능이 달라진다. 너무 크게 잡으면 필요없는 페이지가 메모리에 남아서 다른 프로세스에 영향을 미치고 너무 작게 잡으면 필요한 페이지가 swap out 되어버려 프로세스의 성능이 떨어진다.

#### Page Fault Frequency

working set model의 경우 충분한 페이지를 할당하지 않으면 working set에 있는 페이지를 물리 메모리에 유지 하기가 힘들다. working set model에서는 어떤 프레임을 물리 메모리에 유지해야 하는지는 알 수 있지만, 프로세스에 프레임을 얼마나 할당해야 하는지는 알 수 없다. 따라서 Thrashing을 해결하지는 못한다.

프로세스가 필요한 페이지의 양을 동적으로 결정하는 방법 중 page fualt frequency를 이용하는게 있다. page fault 회수를 기록하여 page fault 비율을 계산하는 방식이다. page fault 비율의 상한과 하한을 설정하고 상한을 초과하면 프레임을 추가하여 늘리고, 하한에 미달되면 할당한 프레임을 회수한다.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fba6BDF%2FbtrmNoR1kMb%2FvTdkrLK8BQlUO1x0zDD3Vk%2Fimg.png)

---

- 요구 페이징이 뭔가요?

- PageFault가 뭔가요?

- Segmentation과 Page fault의 차이?

- 페이지 교체 알고리즘에 대해 아는대로 설명해주세요

- Thrasing이 뭔가요?

- Thrashing 해결하는 방법에 대해 설명해주세요
